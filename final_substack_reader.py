import feedparser
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta
from time import sleep

# === TELEGRAM BOT CONFIG ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# === Hugging Face API Key ===
HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY")

# === Escape Markdown characters for Telegram (MarkdownV2 mode) ===
def escape_markdown(text):
    escape_chars = r"_*[]()~`>#+=|{}.!-"
    return re.sub(f"([{re.escape(escape_chars)}])", r"\\\1", text)

# === Fetch article content from URL ===
def get_article_content(url, retries=3, timeout=10):
    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=timeout)
        soup = BeautifulSoup(response.content, "html.parser")
        content_div = soup.find("div", class_="body") or soup.find("article")
        return content_div.get_text(separator="\n", strip=True) if content_div else "Content not found."
    except requests.exceptions.Timeout:
        if retries > 0:
            sleep(2)
            return get_article_content(url, retries-1)
        return "Timeout fetching article."
    except Exception as e:
        return f"Error fetching article: {e}"

# === Summarize article using Hugging Face API ===
def summarize_article(content):
    api_url = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
    headers_llama = {
        "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
        "Content-Type": "application/json"
    }
    prompt = (
        "You are an expert in content analysis and summarization. Read the following Substack article content "
        "and summarize it in 4-6 succinct, insightful bullet points. Focus on the core arguments, key insights, "
        "and actionable takeaways. Present the summary in a professional, high-level tone, avoiding unnecessary details "
        "and providing a clear and concise overview of the article's most important points.\n\n"
        f"Article:\n{content}\n\nSummary:"
    )
    payload = {"inputs": prompt, "parameters": {"max_new_tokens": 300}}

    try:
        response = requests.post(api_url, headers=headers_llama, json=payload)
        result = response.json()
        if isinstance(result, dict) and "error" in result:
            return f"API Error: {result['error']}"
        return result[0]['generated_text'].split(prompt)[-1].strip()
    except Exception as e:
        return f"Error summarizing: {e}"

# === Send message(s) to Telegram with automatic splitting ===
def send_telegram_messages(full_text):
    chunks = []
    while full_text:
        if len(full_text) <= 4096:
            chunks.append(full_text)
            break
        split_index = full_text.rfind("\n---\n", 0, 4096)
        if split_index == -1:
            split_index = 4096
        chunks.append(full_text[:split_index])
        full_text = full_text[split_index:].lstrip()

    for idx, chunk in enumerate(chunks):
        escaped_chunk = escape_markdown(chunk)
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": escaped_chunk,
            "parse_mode": "MarkdownV2"
        }
        res = requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage", json=payload)
        if res.status_code == 200:
            print(f"âœ… Message {idx + 1} sent.")
        else:
            print(f"âŒ Telegram error in chunk {idx + 1}: {res.json()}")

# === Get yesterday's date ===
yesterday = (datetime.now() - timedelta(days=1)).date()

# === Load feed URLs from file ===
with open("clean_substack_feeds.txt", "r") as f:
    feeds = [line.strip() for line in f if line.strip()]

# === Initialize message text ===
full_message = "ðŸ“° *Substack Summary Bot*\n\n"

# === Loop through feeds and summarize yesterday's posts ===
for feed_url in feeds:
    print(f"\nFetching RSS feed: {feed_url}...")
    try:
        response = requests.get(feed_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        feed = feedparser.parse(response.content)
    except requests.exceptions.Timeout:
        print(f"âŒ Timeout fetching feed: {feed_url}")
        continue
    except Exception as e:
        print(f"âŒ Failed to fetch feed {feed_url}: {e}")
        continue

    for entry in feed.entries:
        published_str = entry.get("published", "")
        if 'GMT' in published_str:
            published_str = published_str.replace('GMT', '+0000')

        try:
            pub_date = datetime.strptime(published_str, "%a, %d %b %Y %H:%M:%S %z").date()
        except Exception as e:
            print(f"âš ï¸ Skipping '{entry.get('title')}' due to date parsing error: {e}")
            continue

        if pub_date == yesterday:
            print(f"âœ… Found: {entry.title}")
            content = get_article_content(entry.link)
            summary = summarize_article(content)
            full_message += f"*{entry.title}*\n{entry.link}\n_{summary}_\n\n---\n"

# === Send the message(s) ===
if full_message.strip() == "ðŸ“° *Substack Summary Bot*":
    send_telegram_messages("ðŸ“° *Substack Summary Bot*\n\nNo new posts found for yesterday.")
else:
    send_telegram_messages(full_message)
